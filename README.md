# Algomo

## FAQ/QnA Web Scraping

The goal of this project is to scrape question-answer pairs data on the internet


### Folder Structure
    .
    ├── data                    # Data generated by notebooks
    ├── WebScraping.ipynb       # Codes with solution explainations
    ├── WebScraping.html        # HTML version of codes with solution explainations
    ├── LICENSE
    └── README.md

### Built With
This section list all frameworks/libraries used.
- pandas==1.4.4
- requests
- bs4

<!-- GETTING STARTED -->
## Getting Started

### Scrapping
You can find the details in the notebook.
1. Setup a list of startings urls

```
starting_urls = ['https://support.n26.com/de-de',
                 'https://support.n26.com/de-at',
                 'https://support.n26.com/en-at',
                 'https://support.n26.com/en-de',
                 'https://support.n26.com/en-it',
                 'https://support.n26.com/it-it',
                 'https://support.n26.com/en-eu',
                 'https://support.n26.com/en-fr',
                 'https://support.n26.com/fr-fr',
                 'https://support.n26.com/en-es',
                 'https://support.n26.com/es-es',
                 'https://support.n26.com/en-us',
                 'https://support.n26.com/en-gb'
                ]
```

2. Initialize a storage folder with name 'website'

```
build_input_urls_storage(starting_urls, website="n26")
```

3. Start scrapping

```
parsed_data_path = crawl_url_and_content(root='https://support.n26.com', website="n26")

```

## License
Distributed under the MIT License. See `LICENSE.txt` for more information.
